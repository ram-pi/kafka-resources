@baseUrl = http://localhost:28083
@connectorName = replicator

### Plugins
GET {{baseUrl}}/connector-plugins HTTP/1.1

### GET STATUS
GET {{baseUrl}}/connectors/{{connectorName}}/status

### DESCRIBE
GET {{baseUrl}}/connectors/{{connectorName}}

### GET CONNECTORS LIST
GET {{baseUrl}}/connectors

### STOP
DELETE {{baseUrl}}/connectors/{{connectorName}} HTTP/1.1

### Create replicator instance
PUT {{baseUrl}}/connectors/{{connectorName}}/config HTTP/1.1
Content-Type: application/json

{
    "connector.class": "io.confluent.connect.replicator.ReplicatorSourceConnector",
    "topic.whitelist": "pageviews",
    "key.converter": "io.confluent.connect.replicator.util.ByteArrayConverter",
    "value.converter": "io.confluent.connect.replicator.util.ByteArrayConverter",
    "src.kafka.bootstrap.servers": "kafka-dc1:9092",
    "src.consumer.group.id": "replicator-dc2-to-dc1-topic1",
    "src.consumer.confluent.monitoring.interceptor.bootstrap.servers": "kafka-dc1:9092",
    "src.kafka.timestamps.topic.replication.factor": 1,
    "src.kafka.timestamps.producer.confluent.monitoring.interceptor.bootstrap.servers": "kafka-dc1:9092",
    "src.kafka.timestamps.producer.interceptor.classes": "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor",
    "src.consumer.interceptor.classes": "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor",
    "dest.kafka.timestamps.producer.interceptor.classes": "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor",
    "dest.consumer.interceptor.classes": "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor",
    "dest.kafka.bootstrap.servers": "kafka-dc2:9092",
    "error.tolerance": "all",
    "errors.log.enable": "true",
    "errors.log.include.messages": "true",
    "confluent.topic.replication.factor": 1,
    "provenance.header.enable": "true",
    "topic.timestamp.type": "LogAppendTime",
    "header.converter": "io.confluent.connect.replicator.util.ByteArrayConverter",
    "tasks.max": "1"
}

### Create replicator instance
PUT {{baseUrl}}/connectors/{{connectorName}}-avro/config HTTP/1.1
Content-Type: application/json

{
    "connector.class": "io.confluent.connect.replicator.ReplicatorSourceConnector",
    "topic.whitelist": "pageviews",
    "_src.key.converter": "org.apache.kafka.connect.storage.StringConverter",
    "_src.value.converter": "io.confluent.connect.avro.AvroConverter",
    "_src.value.converter.schema.registry.url": "http://schema-registry:8081",
    "key.converter": "org.apache.kafka.connect.storage.StringConverter",
    "value.converter": "io.confluent.connect.avro.AvroConverter",
    "value.converter.schema.registry.url": "http://schema-registry:8081",
    "src.kafka.bootstrap.servers": "kafka-dc1:9092",
    "src.consumer.group.id": "replicator-dc2-to-dc1-topic1",
    "src.kafka.timestamps.topic.replication.factor": 1,
    "error.tolerance": "all",
    "errors.log.enable": "true",
    "errors.log.include.messages": "true",
    "confluent.topic.replication.factor": 1,
    "provenance.header.enable": "true",
    "topic.timestamp.type": "LogAppendTime",
    "header.converter": "io.confluent.connect.replicator.util.ByteArrayConverter",
    "topic.rename.format": "${topic}-avro",
    "topic.auto.create": "true",
    "tasks.max": "1"
}

### STOP
DELETE {{baseUrl}}/connectors/{{connectorName}}-avro HTTP/1.1

### GET STATUS
GET {{baseUrl}}/connectors/{{connectorName}}-avro/status

### REPLICATOR METRICS
GET {{baseUrl}}/ReplicatorMetrics

### WORKER METRICS
GET {{baseUrl}}/WorkerMetrics/replicator

### WORKER METRICS GENERAL
GET {{baseUrl}}/WorkerMetrics/